---
title: "My Take on AI Use and Adoption"
author: "Natalie"
description: "How I think about AI use and avoid the slop"
---

# My Philosophy on AI Usage and Adoption

I work with AI every day, hell I probably talk to ChatGPT more than some of my relatives. It's tempting to use it everywhere and it feels damn good when it works. I probably use it too much.

## My Three Criteria

I'll feel good about using AI for something if it checks all three of these boxes:

### 1. The tasks result that is self-evident or able to be quickly verified

If I can't tell right away if the output isn't slop it just feels bad. Doing a bunch of research to verify the model didn't spit out garbage isn't how I want to spend my time. I'll probably either get annoyed or waste more time checking it's work than doing it myself.

**Good examples:**

- Generating code that you can immediately run and test
- Summarizing content you're already familiar with

**Bad examples:**

- Medical diagnoses
- Research on topics you know nothing about

Point is that checking should be quick. If verifying takes longer than just doing it yourself, you're not saving any time.

### 2. A tolerance for error

AI gets things wrong _constantly_. Sometimes it's obvious, sometimes it's subtle. If a mistake could cost me money, damage my reputation, or piss off my coworkers I should probably be more careful than I am.

**Good examples:**

- Drafting initial versions of emails or documents
- Generating ideas or brainstorming
- Writing test cases or boilerplate code
- Creating first drafts of blog posts (like this one!)

**Bad examples:**

- Final code reviews without human oversight
- Critical business decisions
- Personal information handling without verification
- Anything that goes directly to customers without review

You can still use AI for important work, but you need to review it. How much review depends on how bad a mistake would be.

### 3. It's time-consuming or annoying

If something is quick, fun, or a good way to learn, I’d should probably just do it myself...

But I'm a flawed person and instead usually keep pulling the slop lever.

Just one more prompt...

Come on it was so close that time...

Maybe if I just throw these couple of files at it...

![Me realizing I should just do it myself](/awdangit.png)

Hey Natalie you know you could just write that function yourself it's like basically a one liner.

**Shutup** I'm saving time.

**Good examples:**

- Repetitive data entry or formatting
- Writing boilerplate code
- Converting between formats or rewriting things in some equivalent fashion
- Tasks you've done many times before

**Bad examples:**

- That one task that it's so close to one shotting...
- You know that one like it's so close, it's basically right...
- It just needs to just understand that one other thing...
- You don't get it the AI is going to work this time...

The annoying part matters. If you hate doing something repetitive, that's perfect for AI. But if it's interesting or you'll learn from it, you're probably better off doing it yourself.

## Putting It All Together

When all three criteria match, AI actually helps. When they don't, you're either wasting time, taking unnecessary risks, or skipping something you should learn.

I use this checklist all the time—at work and on personal projects. It keeps me from using AI just because I can, while still getting value where it makes sense.

The point isn't to avoid AI, but to be honest about when it actually helps versus when it just adds complexity.
